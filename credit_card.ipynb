{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT THE DEPENDENCIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#loading tha dataset to a pandas dataframe\n",
    "credit_card_data = pd.read_csv(\"C:/Users/asus/Credit_card_fraud_detection/creditcard.csv\")\n",
    "\n",
    "#first 5 rows of dataset\n",
    "\n",
    "credit_card_data.head()\n",
    "\n",
    "credit_card_data.tail()\n",
    "\n",
    "#dataset information\n",
    "credit_card_data.info()\n",
    "\n",
    "credit_card_data.isnull().sum()\n",
    "\n",
    "credit_card_data['Class'].value_counts()\n",
    "\n",
    "#separating the data for analysis\n",
    "legit= credit_card_data[credit_card_data.Class == 0]\n",
    "fraud= credit_card_data[credit_card_data.Class == 1]\n",
    "\n",
    "print(legit.shape)\n",
    "print(fraud.shape)\n",
    "\n",
    "legit.Amount.describe()\n",
    "\n",
    "fraud.Amount.describe()\n",
    "\n",
    "\n",
    " #compare the values for both of the transactions\n",
    "credit_card_data.groupby('Class').mean()\n",
    "\n",
    "'Under-Sampling'\n",
    "\n",
    "\n",
    "'Build a Sample Dataset conatining similar distribution of normal transactions and fraudulent transactions'\n",
    "\n",
    "legit_sample= legit.sample(n=492)\n",
    "\n",
    "'Concatinating two data frames with N=492'\n",
    "\n",
    "new = pd.concat([legit_sample , fraud], axis=0)\n",
    "\n",
    "new.head()\n",
    "\n",
    "new.tail()\n",
    "\n",
    "new['Class'].value_counts()\n",
    "\n",
    "new.groupby('Class').mean()\n",
    "#this tells us that the nature of the data is not changed and it will greatly help in training the model\n",
    "\n",
    "\n",
    "X= new.drop(columns ='Class', axis=1)\n",
    "Y= new['Class']\n",
    "\n",
    "print(X)\n",
    "\n",
    "#now splitting the data into training and testing data\n",
    "\n",
    "X_train , X_test, Y_train, Y_test = train_test_split(X, Y , test_size=0.2, stratify=Y, random_state=2)\n",
    "\n",
    "print(X.shape, X_train.shape, X_test.shape)\n",
    "\n",
    "print(Y.shape , Y_train)\n",
    "\n",
    "'LOGISTIC REGRESSION'\n",
    "\n",
    "model= LogisticRegression()\n",
    "\n",
    "#training the logistic regession model with training data\n",
    "model.fit(X_train , Y_train)\n",
    "\n",
    "#accuracy on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy=accuracy_score(X_train_prediction, Y_train)\n",
    "\n",
    "print('Accuracy on Training data : ', training_data_accuracy)\n",
    "\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "\n",
    "print('Accuracy score on Test Data : ', test_data_accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
